# -*- coding: utf-8 -*-
"""Baseline_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QWxhv5u6-JUM8TJuOJNwZ9Zw5QXKqP31
"""

import zipfile
import io
import numpy as np
import librosa
import librosa.display
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from io import BytesIO

# Define emotions mapping based on RAVDESS naming conventions
emotion_dict = {
    '01': 'neutral', '02': 'calm', '03': 'happy', '04': 'sad',
    '05': 'angry', '06': 'fearful', '07': 'disgust', '08': 'surprised'
}

# Extended feature extraction function combining multiple features
def extract_features(file_obj):
    # Load audio data from BytesIO object
    y, sr = librosa.load(file_obj, sr=None)
    # Extract various features
    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13), axis=1)
    chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr), axis=1)
    mel_spec = np.mean(librosa.feature.melspectrogram(y=y, sr=sr), axis=1)
    spectral_contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr), axis=1)
    return np.hstack([mfccs, chroma, mel_spec, spectral_contrast])

# Update this path to the correct location of your ZIP file
zip_path = r"Audio_Song_Actors_01-24.zip"

# Check if the file exists before proceeding
if not os.path.exists(zip_path):
    raise FileNotFoundError(f"The file '{zip_path}' was not found. Please check the file path and try again.")

# Load dataset from ZIP file
features, labels = [], []
try:
    with zipfile.ZipFile(zip_path, 'r') as archive:
        # Filter only .wav files
        file_list = [f for f in archive.namelist() if f.endswith(".wav")]
        for file in file_list:
            # Extract filename and emotion code
            filename = file.split("/")[-1]
            emotion_code = filename.split("-")[2]
            if emotion_code in emotion_dict:
                with archive.open(file) as audio_file:
                    with BytesIO(audio_file.read()) as audio_data:
                        feature = extract_features(audio_data)
                        features.append(feature)
                        labels.append(emotion_dict[emotion_code])
except Exception as e:
    raise RuntimeError(f"An error occurred while processing the ZIP file: {e}")

# Create DataFrame from extracted features
data = pd.DataFrame(features)
data['label'] = labels

# Encode labels
label_encoder = LabelEncoder()
data['label'] = label_encoder.fit_transform(data['label'])

# Split dataset
X = data.drop(columns=['label'])
y = data['label']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Set up hyperparameter grid for SVM with RBF kernel
param_grid = {
    'C': [1, 10, 50, 100],
    'gamma': [0.001, 0.01, 0.1, 1]
}

# Initialize SVM and GridSearchCV
svm = SVC(kernel='rbf')
grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)
grid_search.fit(X_train, y_train)

# Best estimator from grid search
best_svm = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Make predictions
y_pred = best_svm.predict(X_test)

# Evaluate performance
accuracy = accuracy_score(y_test, y_pred)
print(f"\nAccuracy: {accuracy:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Plot Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt="d",
            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

